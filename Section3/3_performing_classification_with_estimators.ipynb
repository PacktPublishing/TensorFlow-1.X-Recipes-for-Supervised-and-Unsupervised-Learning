{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Classification with Estimators API (tf.contrib.learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "## Training data\n",
    "train_dataset_path = os.path.join(os.getcwd(), os.pardir, 'data', 'small_higgs.csv')\n",
    "higgs_train = genfromtxt(train_dataset_path, delimiter=',')\n",
    "X_train = higgs_train[:,1:]\n",
    "y_train = higgs_train[:,0]\n",
    "del higgs_train\n",
    "\n",
    "# Validation data\n",
    "validation_dataset_path = os.path.join(os.getcwd(), os.pardir, 'data', 'validation_higgs.csv')\n",
    "higgs_val = genfromtxt(validation_dataset_path, delimiter=',')\n",
    "X_val = higgs_val[:,1:]\n",
    "y_val = higgs_val[:,0]\n",
    "del higgs_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write one or more dataset importing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = ['lepton_pT', 'lepton_eta', 'lepton_phi', 'missing_energy_magnitude',\n",
    "                 'missing_energy_phi', 'jet_1_pt', 'jet_1_eta', 'jet_1_phi', 'jet_1_b_tag',\n",
    "                 'jet_2_pt', 'jet_2_eta', 'jet_2_phi', 'jet_2_b_tag', 'jet_3_pt', 'jet_3_eta',\n",
    "                 'jet_3_phi', 'jet_3_b_tag', 'jet_4_pt', 'jet_4_eta', 'jet_4_phi', 'jet_4_b_tag',\n",
    "                  'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 400\n",
    "## This is a dict containing names and the corresponding columns:\n",
    "train_features_dict = {name: col for name, col in zip(feature_names, X_train.T)}\n",
    "\n",
    "## Training input function\n",
    "input_fn_train = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=train_features_dict,\n",
    "    y=y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=N_EPOCHS,\n",
    "    shuffle = True)\n",
    "\n",
    "## Validation input function\n",
    "val_features_dict = {name:col for name, col in zip(feature_names, X_val.T)}\n",
    "\n",
    "input_fn_val = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=val_features_dict,\n",
    "    y=y_val,\n",
    "    num_epochs=1,\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the feature columnsÂ¶\n",
    "\n",
    "Remember:\n",
    "> when defining a feature column like: `tf.feature_column.numeric_column('feature_1')` the string `feature_1` must also be a key in the `train_features_dict` and `test_features_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numeric_feature_cols = [tf.feature_column.numeric_column(col) for col in feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Instantiate the DNNClassifier Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './high_level_api_classification', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001DC5FD72630>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "higgs_model = tf.estimator.DNNClassifier(\n",
    "    feature_columns=numeric_feature_cols,\n",
    "    hidden_units=[200, 200, 200],\n",
    "    model_dir='./high_level_api_classification',\n",
    "    dropout = 0.2, # In the last section we used keep_prob=0.8, hence dropout=1-keep_prob = 1-.8 = 0.2\n",
    "    optimizer='Adagrad',\n",
    "    activation_fn=tf.nn.elu)\n",
    "# Loss is calculated by using softmax cross entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./high_level_api_classification\\model.ckpt.\n",
      "INFO:tensorflow:loss = 97.729, step = 1\n",
      "INFO:tensorflow:global_step/sec: 137.565\n",
      "INFO:tensorflow:loss = 93.2399, step = 101 (0.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.011\n",
      "INFO:tensorflow:loss = 92.7844, step = 201 (0.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.47\n",
      "INFO:tensorflow:loss = 93.4877, step = 301 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.725\n",
      "INFO:tensorflow:loss = 86.9227, step = 401 (0.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.85\n",
      "INFO:tensorflow:loss = 85.7106, step = 501 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.725\n",
      "INFO:tensorflow:loss = 91.7221, step = 601 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.15\n",
      "INFO:tensorflow:loss = 90.2454, step = 701 (0.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.328\n",
      "INFO:tensorflow:loss = 88.9947, step = 801 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.672\n",
      "INFO:tensorflow:loss = 80.916, step = 901 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.067\n",
      "INFO:tensorflow:loss = 82.5073, step = 1001 (0.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.075\n",
      "INFO:tensorflow:loss = 86.6206, step = 1101 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.419\n",
      "INFO:tensorflow:loss = 83.0238, step = 1201 (0.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.38\n",
      "INFO:tensorflow:loss = 85.1814, step = 1301 (0.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.768\n",
      "INFO:tensorflow:loss = 84.3573, step = 1401 (0.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.725\n",
      "INFO:tensorflow:loss = 81.6015, step = 1501 (0.539 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1563 into ./high_level_api_classification\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 46.2987.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1dc5fd72940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higgs_model.train(input_fn=input_fn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize/analyze the results of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-12-14:40:39\n",
      "INFO:tensorflow:Restoring parameters from ./high_level_api_classification\\model.ckpt-1563\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-12-14:40:40\n",
      "INFO:tensorflow:Saving dict for global step 1563: accuracy = 0.6374, accuracy_baseline = 0.535, auc = 0.694428, auc_precision_recall = 0.710696, average_loss = 0.62848, global_step = 1563, label/mean = 0.535, loss = 78.56, prediction/mean = 0.562754\n"
     ]
    }
   ],
   "source": [
    "higgs_model.evaluate(input_fn=input_fn_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
